<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Stereo Photogrammetry for River Monitoring</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>Stereo photogrammetry for river water level and cross-section update: classical and deep learning approaches</h1>
        <div class="authors">
            <p>
                <a href="#">Pedro Alberto Pereira Zamboni</a>,
                <a href="#">Robert Krüger</a>,
                <a href="#">Anette Eltner</a>
            </p>
        </div>
        <div class="affiliations">
            <p>Institute of Photogrammetry and Remote Sensing, Dresden University of Technology, Dresden, Germany</p>
        </div>
    </header>

    <nav>
        <a href="#about">About</a>
        <a href="#methodology">Methodology</a>
        <a href="#results">Results</a>
        <a href="#info">Event Info</a>
        <a href="https://doi.org/10.5194/egusphere-egu25-9375">Paper</a>
    </nav>

    <main>
        <section id="about">
            <h2>About</h2>
            <p>Traditional water level monitoring relies on intrusive gauging methods like pressure gauges, which are vulnerable to loss during intense floods. Camera gauges have emerged as a promising alternative, offering remote sensing capabilities and safer installation options. However, common single-camera setups require additional information such as 3D models and ground control points.</p>
            
            <p>This research introduces a novel approach using stereo-photogrammetry with two cameras. This setup eliminates the need for pre-existing 3D models, requiring only the distance between cameras (baseline) and interior camera geometry. The method enables direct 3D reconstruction of river cross-sections and water levels, supporting both traditional photogrammetric techniques and modern deep learning approaches.</p>
        </section>

        <section id="methodology">
            <h2>Methodology</h2>
            <div class="image-container">
                <img src="images/Slide5.PNG" alt="Classical Stereo Processing Pipeline">
                <p class="caption">Classical stereo processing pipeline showing the key steps in stereo reconstruction</p>
            </div>
            <div class="image-container">
                <img src="images/Slide9.PNG" alt="Deep Learning Stereo Processing">
                <p class="caption">Deep learning approach utilizing neural networks for improved feature matching</p>
            </div>
        </section>

        <section id="results">
            <h2>Results & Applications</h2>
            <div class="image-container">
                <img src="images/Slide10.PNG" alt="Z-coordinate Comparison">
                <p class="caption">Validation: Z-coordinate comparison between models and reference points</p>
            </div>
            <div class="image-container">
                <img src="images/Slide14.PNG" alt="Water Level and Discharge Measurement">
                <p class="caption">Practical application: Water level and discharge measurement system</p>
            </div>
        </section>

        <section id="info">
            <h2>Event Information</h2>
            <div class="event-details">
                <p><strong>Event:</strong> EGU General Assembly 2025</p>
                <p><strong>Location:</strong> Vienna, Austria</p>
                <p><strong>Date:</strong> 27 Apr–2 May 2025</p>
                <p><strong>Session:</strong> <a href="https://meetingorganizer.copernicus.org/EGU25/session/53961">HS1.2.1</a></p>
                <p><strong>Abstract:</strong> EGU25-9375</p>
                <p><strong>DOI:</strong> <a href="https://doi.org/10.5194/egusphere-egu25-9375">10.5194/egusphere-egu25-9375</a></p>
            </div>
        </section>
    </main>

    <style>
    .image-container {
        margin: 2rem 0;
        text-align: center;
    }
    
    .image-container img {
        max-width: 100%;
        height: auto;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    
    .caption {
        margin-top: 1rem;
        font-size: 0.9rem;
        color: var(--secondary-color);
    }

    .event-details {
        background-color: #f8f9fa;
        padding: 1.5rem;
        border-radius: 8px;
        border-left: 4px solid var(--accent-color);
    }

    .event-details p {
        margin: 0.5rem 0;
    }

    .event-details strong {
        color: var(--primary-color);
        margin-right: 0.5rem;
    }
    </style>

    <footer>
        <p>© 2025 Author(s). This work is distributed under the <a href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 License</a></p>
        <p>EGU General Assembly 2025</p>
        <p>DOI: <a href="https://doi.org/10.5194/egusphere-egu25-9375">10.5194/egusphere-egu25-9375</a></p>
    </footer>
</body>
</html>
